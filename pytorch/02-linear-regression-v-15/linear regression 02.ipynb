{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yield_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "# yield_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
    "# if we see the above linear reg equations we can see that w is representing matrix and b is representing vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2023,  1.3672,  0.0169],\n",
      "        [ 1.0684,  1.3708, -0.9042]], requires_grad=True)\n",
      "tensor([-0.3253, -1.7143], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# weights and biases\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b   # @ = matrix multiplication  w.t() = transpose of w ie (m,n) -> (n,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 77.2321, 129.2411],\n",
      "        [102.6561, 158.2705],\n",
      "        [166.2532, 222.4806],\n",
      "        [ 38.4506, 132.7498],\n",
      "        [118.1466, 140.3073]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(t1,t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff)/diff.numel()    # .numel() returns the number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2807.0913, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute Loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(52.9820, grad_fn=<SqrtBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = torch.sqrt(loss)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust weights and biases using gradient descent\n",
    "\n",
    "We'll reduce the loss and improve our model using the gradient descent optimization algorithm, which has the following steps:\n",
    "\n",
    "1. Generate predictions\n",
    "\n",
    "2. Calculate the loss\n",
    "\n",
    "3. Compute gradients w.r.t the weights and biases\n",
    "\n",
    "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "5. Reset the gradients to zero\n",
    "\n",
    "Let's implement the above step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 77.2321, 129.2411],\n",
      "        [102.6561, 158.2705],\n",
      "        [166.2532, 222.4806],\n",
      "        [ 38.4506, 132.7498],\n",
      "        [118.1466, 140.3073]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 1) Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2807.0913, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 2) Calculate the loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2070.9502, 2364.3325, 1341.7174],\n",
      "        [5711.5420, 5432.4194, 3287.3608]])\n",
      "tensor([24.3477, 64.6099])\n"
     ]
    }
   ],
   "source": [
    "# 3) Compute gradients w.r.t the weights and biases\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2231,  1.3435,  0.0035],\n",
      "        [ 1.0113,  1.3165, -0.9371]], requires_grad=True)\n",
      "tensor([-0.3256, -1.7149], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.5590, 120.0178],\n",
      "        [ 97.8320, 146.1879],\n",
      "        [160.5048, 208.3248],\n",
      "        [ 34.8249, 123.3711],\n",
      "        [113.5084, 128.8493]], grad_fn=<AddBackward0>)\n",
      "tensor(2036.3707, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "print(preds)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)   # we can see that the loss has reduced by some amount  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets iterate through 100 epochs\n",
    "for i in range(100):   # 100 epochs is a hyperparameter\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5   # 1e-5 is also a hyperparameter we can give or change as our wish\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(263.9421, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# verify loss now\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)    # loss is much lower now and thats great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 57.1495,  74.8783],\n",
      "        [ 76.5800,  89.9573],\n",
      "        [131.5145, 149.9718],\n",
      "        [ 20.7423,  63.8535],\n",
      "        [ 92.2651,  84.5001]], grad_fn=<AddBackward0>)\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "print(preds)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using PyTorch built-ins\n",
    "\n",
    "The model and training process above were implemented using basic matrix operations. But since this such a common pattern , PyTorch has several built-in functions and classes to make it easy to create and train models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73.  67.  43.]\n",
      " [ 91.  88.  64.]\n",
      " [ 87. 134.  58.]\n",
      " [102.  43.  37.]\n",
      " [ 69.  96.  70.]\n",
      " [ 73.  67.  43.]\n",
      " [ 91.  88.  64.]\n",
      " [ 87. 134.  58.]\n",
      " [102.  43.  37.]\n",
      " [ 69.  96.  70.]\n",
      " [ 73.  67.  43.]\n",
      " [ 91.  88.  64.]\n",
      " [ 87. 134.  58.]\n",
      " [102.  43.  37.]\n",
      " [ 69.  96.  70.]]\n",
      "[[ 56.  70.]\n",
      " [ 81. 101.]\n",
      " [119. 133.]\n",
      " [ 22.  37.]\n",
      " [103. 119.]\n",
      " [ 56.  70.]\n",
      " [ 81. 101.]\n",
      " [119. 133.]\n",
      " [ 22.  37.]\n",
      " [103. 119.]\n",
      " [ 56.  70.]\n",
      " [ 81. 101.]\n",
      " [119. 133.]\n",
      " [ 22.  37.]\n",
      " [103. 119.]]\n"
     ]
    }
   ],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], \n",
    "                   [102, 43, 37], [69, 96, 70], [73, 67, 43], \n",
    "                   [91, 88, 64], [87, 134, 58], [102, 43, 37], \n",
    "                   [69, 96, 70], [73, 67, 43], [91, 88, 64], \n",
    "                   [87, 134, 58], [102, 43, 37], [69, 96, 70]], \n",
    "                  dtype='float32')\n",
    "\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], [81, 101], [119, 133], \n",
    "                    [22, 37], [103, 119], [56, 70], \n",
    "                    [81, 101], [119, 133], [22, 37], \n",
    "                    [103, 119], [56, 70], [81, 101], \n",
    "                    [119, 133], [22, 37], [103, 119]], \n",
    "                   dtype='float32')\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert it into tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]), tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs,targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 91.,  88.,  64.],\n",
       "         [ 73.,  67.,  43.],\n",
       "         [102.,  43.,  37.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]), tensor([[ 81., 101.],\n",
       "         [ 56.,  70.],\n",
       "         [ 22.,  37.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[[1,5,3,6,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data Loader\n",
    "batch_size = 5    # divide or split the whole data into batches of 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch:\n",
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [ 91.,  88.,  64.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [119., 133.],\n",
      "        [ 81., 101.]])\n",
      "Batch:\n",
      "tensor([[ 69.,  96.,  70.],\n",
      "        [ 69.,  96.,  70.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[103., 119.],\n",
      "        [103., 119.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n",
      "Batch:\n",
      "tensor([[ 73.,  67.,  43.],\n",
      "        [102.,  43.,  37.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 22.,  37.],\n",
      "        [ 22.,  37.],\n",
      "        [ 56.,  70.],\n",
      "        [ 81., 101.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(\"Batch:\")\n",
    "    print(xb)\n",
    "    print(yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1260,  0.2871,  0.0093],\n",
      "        [ 0.3002,  0.1276,  0.4678]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1422,  0.4869], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = nn.Linear(3,2) # 3 are number of inputs and 2 are number of targets\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1260,  0.2871,  0.0093],\n",
       "         [ 0.3002,  0.1276,  0.4678]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1422,  0.4869], requires_grad=True)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.2965, 51.0612],\n",
       "        [14.2535, 68.9671],\n",
       "        [27.9094, 70.8268],\n",
       "        [-0.3049, 53.8978],\n",
       "        [19.3788, 66.1908],\n",
       "        [10.2965, 51.0612],\n",
       "        [14.2535, 68.9671],\n",
       "        [27.9094, 70.8268],\n",
       "        [-0.3049, 53.8978],\n",
       "        [19.3788, 66.1908],\n",
       "        [10.2965, 51.0612],\n",
       "        [14.2535, 68.9671],\n",
       "        [27.9094, 70.8268],\n",
       "        [-0.3049, 53.8978],\n",
       "        [19.3788, 66.1908]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build-in loss function\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss funcion\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3065.6050, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(model(inputs),targets)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer (stochastic gradient descent)\n",
    "\n",
    "opt = torch.optim.SGD(model.parameters(), lr = 1e-5)  # we need to pass weights and bias matrices ie model.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "We are now ready to train the model. We'll follow the exact same process to implement gradient descent:\n",
    "\n",
    "1. Generate predictions\n",
    "\n",
    "2. Calculate the loss\n",
    "\n",
    "3. Compute gradients w.r.t the weights and biases\n",
    "\n",
    "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "5. Reset the gradients to zero\n",
    "\n",
    "The only change is that we'll work batches of data, instead of processing the entire training data in every iteration. Let's define a utility function `fit` which trains the model for a given number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    min_loss = 999999\n",
    "    at_epoch = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            # Generate predictions\n",
    "            preds = model(xb)\n",
    "            \n",
    "            # Calculate the loss\n",
    "            loss = loss_fn(preds, yb)\n",
    "            \n",
    "            # Compute gradients w.r.t the weights and biases\n",
    "            loss.backward()\n",
    "            \n",
    "            # Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "            opt.step()\n",
    "            \n",
    "            # Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "        if min_loss > loss.item():\n",
    "            min_loss = loss.item()\n",
    "            at_epoch = epoch+1\n",
    "    print('Min Loss at Epoch [{}/{}], Loss: {:.4f}'.format(at_epoch, num_epochs, min_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 14.1527\n",
      "Epoch [20/100], Loss: 2.9620\n",
      "Epoch [30/100], Loss: 10.1879\n",
      "Epoch [40/100], Loss: 8.8275\n",
      "Epoch [50/100], Loss: 8.1289\n",
      "Epoch [60/100], Loss: 6.4297\n",
      "Epoch [70/100], Loss: 3.0755\n",
      "Epoch [80/100], Loss: 9.2591\n",
      "Epoch [90/100], Loss: 2.4511\n",
      "Epoch [100/100], Loss: 6.5072\n",
      "Min Loss at Epoch [93/100], Loss: 1.3945\n"
     ]
    }
   ],
   "source": [
    "fit(100, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.4294,  70.6527],\n",
       "        [ 80.4155,  99.5699],\n",
       "        [122.1076, 134.7381],\n",
       "        [ 22.7425,  38.5444],\n",
       "        [ 97.8237, 116.4392],\n",
       "        [ 57.4294,  70.6527],\n",
       "        [ 80.4155,  99.5699],\n",
       "        [122.1076, 134.7381],\n",
       "        [ 22.7425,  38.5444],\n",
       "        [ 97.8237, 116.4392],\n",
       "        [ 57.4294,  70.6527],\n",
       "        [ 80.4155,  99.5699],\n",
       "        [122.1076, 134.7381],\n",
       "        [ 22.7425,  38.5444],\n",
       "        [ 97.8237, 116.4392]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
